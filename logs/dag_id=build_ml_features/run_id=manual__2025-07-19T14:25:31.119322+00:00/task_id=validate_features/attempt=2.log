[2025-07-19T14:30:38.356+0000] {taskinstance.py:1956} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: build_ml_features.validate_features manual__2025-07-19T14:25:31.119322+00:00 [queued]>
[2025-07-19T14:30:38.359+0000] {taskinstance.py:1956} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: build_ml_features.validate_features manual__2025-07-19T14:25:31.119322+00:00 [queued]>
[2025-07-19T14:30:38.359+0000] {taskinstance.py:2170} INFO - Starting attempt 2 of 2
[2025-07-19T14:30:38.362+0000] {taskinstance.py:2191} INFO - Executing <Task(_PythonDecoratedOperator): validate_features> on 2025-07-19 14:25:31.119322+00:00
[2025-07-19T14:30:38.366+0000] {standard_task_runner.py:60} INFO - Started process 249 to run task
[2025-07-19T14:30:38.369+0000] {standard_task_runner.py:87} INFO - Running: ['***', 'tasks', 'run', 'build_ml_features', 'validate_features', 'manual__2025-07-19T14:25:31.119322+00:00', '--job-id', '118', '--raw', '--subdir', 'DAGS_FOLDER/build_ml_features_dag.py', '--cfg-path', '/tmp/tmphy7oq8uk']
[2025-07-19T14:30:38.369+0000] {standard_task_runner.py:88} INFO - Job 118: Subtask validate_features
[2025-07-19T14:30:38.389+0000] {task_command.py:423} INFO - Running <TaskInstance: build_ml_features.validate_features manual__2025-07-19T14:25:31.119322+00:00 [running]> on host 1b29f8b0fcb6
[2025-07-19T14:30:38.417+0000] {taskinstance.py:2480} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='data-platform' AIRFLOW_CTX_DAG_ID='build_ml_features' AIRFLOW_CTX_TASK_ID='validate_features' AIRFLOW_CTX_EXECUTION_DATE='2025-07-19T14:25:31.119322+00:00' AIRFLOW_CTX_TRY_NUMBER='2' AIRFLOW_CTX_DAG_RUN_ID='manual__2025-07-19T14:25:31.119322+00:00'
[2025-07-19T14:30:38.439+0000] {file_data_context.py:222} INFO - FileDataContext loading fluent config
[2025-07-19T14:30:38.440+0000] {config.py:187} INFO - Loading 'datasources' ->
[{'assets': [...], 'name': 'local_pandas', 'type': 'pandas'}]
[2025-07-19T14:30:38.440+0000] {fluent_base_model.py:276} INFO - _PandasDataAsset.dict() - missing `config_provider`, skipping config substitution
[2025-07-19T14:30:38.441+0000] {taskinstance.py:2698} ERROR - Task failed with exception
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/great_expectations/datasource/fluent/type_lookup.py", line 76, in __getitem__
    return super().__getitem__(key)
  File "/usr/local/lib/python3.8/collections/__init__.py", line 1010, in __getitem__
    raise KeyError(key)
KeyError: 'data_frame'

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/taskinstance.py", line 433, in _execute_task
    result = execute_callable(context=context, **execute_callable_kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/decorators/base.py", line 241, in execute
    return_value = super().execute(context)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/operators/python.py", line 199, in execute
    return_value = self.execute_callable()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/operators/python.py", line 216, in execute_callable
    return self.python_callable(*self.op_args, **self.op_kwargs)
  File "/opt/airflow/dags/build_ml_features_dag.py", line 95, in validate_features
    ctx = gx.get_context()  # GREAT_EXPECTATIONS_HOME already set in image
  File "/home/airflow/.local/lib/python3.8/site-packages/great_expectations/data_context/data_context/context_factory.py", line 263, in get_context
    context = _get_context(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/great_expectations/data_context/data_context/context_factory.py", line 302, in _get_context
    file_context = _get_file_context(
  File "/home/airflow/.local/lib/python3.8/site-packages/great_expectations/data_context/data_context/context_factory.py", line 383, in _get_file_context
    return FileDataContext(
  File "/home/airflow/.local/lib/python3.8/site-packages/great_expectations/data_context/data_context/file_data_context.py", line 67, in __init__
    super().__init__(
  File "/home/airflow/.local/lib/python3.8/site-packages/great_expectations/data_context/data_context/serializable_data_context.py", line 68, in __init__
    super().__init__(runtime_environment=runtime_environment)
  File "/home/airflow/.local/lib/python3.8/site-packages/great_expectations/core/usage_statistics/usage_statistics.py", line 266, in usage_statistics_wrapped_method
    result = func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/great_expectations/data_context/data_context/abstract_data_context.py", line 289, in __init__
    self.fluent_config = self._load_fluent_config(self._config_provider)
  File "/home/airflow/.local/lib/python3.8/site-packages/great_expectations/data_context/data_context/file_data_context.py", line 228, in _load_fluent_config
    gx_config = GxConfig.parse_yaml(path_to_fluent_yaml, _allow_empty=True)
  File "/home/airflow/.local/lib/python3.8/site-packages/great_expectations/datasource/fluent/config.py", line 255, in parse_yaml
    config = cls(**loaded)
  File "/home/airflow/.local/lib/python3.8/site-packages/pydantic/v1/main.py", line 339, in __init__
    values, fields_set, validation_error = validate_model(__pydantic_self__.__class__, data)
  File "/home/airflow/.local/lib/python3.8/site-packages/pydantic/v1/main.py", line 1076, in validate_model
    v_, errors_ = field.validate(value, values, loc=field.alias, cls=cls_)
  File "/home/airflow/.local/lib/python3.8/site-packages/pydantic/v1/fields.py", line 867, in validate
    v, errors = self._apply_validators(v, values, loc, cls, self.pre_validators)
  File "/home/airflow/.local/lib/python3.8/site-packages/pydantic/v1/fields.py", line 1157, in _apply_validators
    v = validator(cls, v, values, self, self.model_config)
  File "/home/airflow/.local/lib/python3.8/site-packages/pydantic/v1/class_validators.py", line 304, in <lambda>
    return lambda cls, v, values, field, config: validator(cls, v)
  File "/home/airflow/.local/lib/python3.8/site-packages/great_expectations/datasource/fluent/config.py", line 209, in _load_datasource_subtype
    datasource = ds_type(**config)
  File "/home/airflow/.local/lib/python3.8/site-packages/pydantic/v1/main.py", line 339, in __init__
    values, fields_set, validation_error = validate_model(__pydantic_self__.__class__, data)
  File "/home/airflow/.local/lib/python3.8/site-packages/pydantic/v1/main.py", line 1076, in validate_model
    v_, errors_ = field.validate(value, values, loc=field.alias, cls=cls_)
  File "/home/airflow/.local/lib/python3.8/site-packages/pydantic/v1/fields.py", line 895, in validate
    v, errors = self._validate_sequence_like(v, values, loc, cls)
  File "/home/airflow/.local/lib/python3.8/site-packages/pydantic/v1/fields.py", line 928, in _validate_sequence_like
    r, ee = self._validate_singleton(v_, values, v_loc, cls)
  File "/home/airflow/.local/lib/python3.8/site-packages/pydantic/v1/fields.py", line 1094, in _validate_singleton
    value, error = field.validate(v, values, loc=loc, cls=cls)
  File "/home/airflow/.local/lib/python3.8/site-packages/pydantic/v1/fields.py", line 898, in validate
    v, errors = self._apply_validators(v, values, loc, cls, self.post_validators)
  File "/home/airflow/.local/lib/python3.8/site-packages/pydantic/v1/fields.py", line 1157, in _apply_validators
    v = validator(cls, v, values, self, self.model_config)
  File "/home/airflow/.local/lib/python3.8/site-packages/pydantic/v1/class_validators.py", line 304, in <lambda>
    return lambda cls, v, values, field, config: validator(cls, v)
  File "/home/airflow/.local/lib/python3.8/site-packages/great_expectations/datasource/fluent/interfaces.py", line 426, in _load_asset_subtype
    asset_type: Type[_DataAssetT] = cls._type_lookup[asset_type_name]
  File "/home/airflow/.local/lib/python3.8/site-packages/great_expectations/datasource/fluent/type_lookup.py", line 81, in __getitem__
    raise KeyError(msg) from key_err
KeyError: 'type data_frame was not found. Available types are: clipboard, csv, excel, feather, fwf, gbq, hdf, html, json, orc, parquet, pickle, sas, spss, sql, sql_query, sql_table, stata, table, xml, dataframe'
[2025-07-19T14:30:38.445+0000] {taskinstance.py:1138} INFO - Marking task as FAILED. dag_id=build_ml_features, task_id=validate_features, execution_date=20250719T142531, start_date=20250719T143038, end_date=20250719T143038
[2025-07-19T14:30:38.448+0000] {standard_task_runner.py:107} ERROR - Failed to execute job 118 for task validate_features ('type data_frame was not found. Available types are: clipboard, csv, excel, feather, fwf, gbq, hdf, html, json, orc, parquet, pickle, sas, spss, sql, sql_query, sql_table, stata, table, xml, dataframe'; 249)
[2025-07-19T14:30:38.470+0000] {local_task_job_runner.py:234} INFO - Task exited with return code 1
[2025-07-19T14:30:38.476+0000] {taskinstance.py:3280} INFO - 0 downstream tasks scheduled from follow-on schedule check
